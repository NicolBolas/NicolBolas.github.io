<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <meta http-equiv="X-UA-Compatible" content="IE=Edge"><title>Chapter&nbsp;7.&nbsp;World in Motion</title><link rel="stylesheet" href="chunked.css" type="text/css"><meta name="generator" content="DocBook XSL-NS Stylesheets V1.75.2"><link rel="home" href="../index.html" title="Learning Modern 3D Graphics Programming"><link rel="up" href="Positioning.html" title="Part&nbsp;II.&nbsp;Positioning"><link rel="prev" href="Tut06 Glossary.html" title="Glossary"><link rel="next" href="Tut07 Primitive Drawing.html" title="Primitive Drawing"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">Chapter&nbsp;7.&nbsp;World in Motion</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="Tut06 Glossary.html">Prev</a>&nbsp;</td><th width="60%" align="center">Part&nbsp;II.&nbsp;Positioning</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="Tut07 Primitive Drawing.html">Next</a></td></tr></table><hr></div><div class="chapter"><div class="titlepage"><div><div><h2 class="title"><a name="d0e6873"></a>Chapter&nbsp;7.&nbsp;World in Motion</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="Tutorial 07.html#d0e6879">World Space</a></span></dt><dt><span class="section"><a href="Tut07 Primitive Drawing.html">Primitive Drawing</a></span></dt><dt><span class="section"><a href="Tut07 Shared Uniforms.html">Shared Uniforms</a></span></dt><dt><span class="section"><a href="Tut07 The Perils of World Space.html">The Perils of World Space</a></span></dt><dt><span class="section"><a href="Tut07 In Review.html">In Review</a></span></dt><dt><span class="section"><a href="Tut07 Glossary.html">Glossary</a></span></dt></dl></div><p>In this tutorial, we will show how to build a world of objects with a dynamic, moving
        camera.</p><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e6879"></a>World Space</h2></div></div></div><p>In the perspective projection tutorial, we defined a projection matrix that transforms
            objects from a specific camera space to clip-space. This camera space was defined
            primarily to make our perspective transformation as simple as possible. The camera
            itself sits immobile at the origin (0, 0, 0). The camera always looks down the Z axis,
            with objects that have a negative Z being considered in front of the camera.</p><p>All of the tutorials we have seen since then have had model transformations that go
            directly to camera space. While this functions, it is not as useful as it could be.
            Camera space is not a particularly flexible space. If we want to have a moving camera,
            obviously something needs to change.</p><p>We could modify our perspective matrix generation functions, so that we can project
            onto a camera that has an arbitrary position and orientation. But really, that's too
            much work; camera space itself works just fine for our needs. It would be easier to just
            introduce an additional transformation.</p><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e6888"></a>Defining the World</h3></div></div></div><p>Right now, the problem is that we transform all of the objects from their
                individual model spaces to camera space directly. The only time the objects are in
                the same space relative to one another is when they are in camera space. So instead,
                we will introduce an intermediate space between model and camera space; let us call
                this space <em class="glossterm">world space.</em></p><p>All objects will be transformed into world space. The camera itself will also have
                a particular position and orientation in world space. And since the camera has a
                known space, with a known position and orientation relative to world space, we have
                a transformation from world space to camera space. This also neatly explains why
                camera space is so named: it is the space where the world is expressed relative to
                the camera.</p><p>So, how do we define world space? Well, we defined model space by fiat: it's the
                space the vertex positions are in. Clip-space was defined for us. The only space
                thus far that we have had a real choice about is camera space. And we defined that
                in a way that gave us the simplest perspective projection matrix.</p><p>The last part gives us a hint. What defines a space is not the matrix that
                transforms to that space, but the matrix that transforms <span class="emphasis"><em>from</em></span>
                that space. And this makes sense; a transformation matrix contains the basis vector
                and origin of the source space, as expressed in the destination coordinate system.
                Defining world space means defining the world-to-camera transform.</p><p>We can define this transform with a matrix. But something said earlier gives us a
                more user-friendly mechanism. We stated that one of the properties of world space is
                that the camera itself has a position and orientation in world space. That position
                and orientation, expressed in world space, comprises the camera-to-world transform;
                do note the order: <span class="quote">&#8220;<span class="quote">camera-to-world.</span>&#8221;</span> We want the opposite:
                world-to-camera.</p><p>The positioning is quite simple. Given the position of the camera in world space,
                the translation component of the world-to-camera matrix is the negation of that.
                This translates world space positions to be relative to the camera's position. So if
                the camera's position in world space is (3, 15, 4), then the translation component
                of the world-to-camera matrix is (-3, -15, -4).</p><p>The orientation is a bit more troublesome. There are many ways to express an
                orientation. In the last tutorial, we expressed it as a rotation about an axis. For
                a camera, it is much more natural to express the orientation relative to something
                more basic: a set of directions.</p><p>What a user most wants to do with a camera is look at something. So the direction
                that is dead center in camera space, that is directly along the -Z axis, is one
                direction vector. Another thing users want to do with cameras is rotate them around
                the viewing direction. So the second direction is the direction that is
                    <span class="quote">&#8220;<span class="quote">up</span>&#8221;</span> in camera space. In camera space, the up direction is
                +Y.</p><p>We could specify a third direction, but that is unnecessary; it is implicit based
                on the other two and a single assumption. Because we want this to be a pure
                orientation matrix, the three basis vectors must be perpendicular to one another.
                Therefore, the third direction is the direction perpendicular to the other two. Of
                course, there are two vectors perpendicular to the two vectors. One goes left
                relative to the camera's orientation and the other goes right. By convention, we
                pick the direction that goes right.</p><p>So we define the camera's orientation (in world space) as being the viewing
                direction and the up direction. Oftentimes, a view direction is not the most useful
                way to orient a camera; it is often useful to select a point in world space to look
                at.</p><p>Therefore, we can define the camera-to-world (again, note the order) transform
                based on the camera's position in the world, a target point to look at in the world,
                and an up direction in the world. To get the world-to-camera transform, we need to
                expend some effort.</p><p>For the sake of reference, here is a diagram of the full transform for vertex
                positions, from the initial attribute loaded from the buffer object, to the final
                window-space position.</p><div class="figure"><a name="d0e6926"></a><p class="title"><b>Figure&nbsp;7.1.&nbsp;Full Vertex Transformation Pipeline</b></p><div class="figure-contents"><div class="mediaobject"><img src="TransformPipeline.svg" alt="Full Vertex Transformation Pipeline"></div></div></div><br class="figure-break"></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e6932"></a>Aerial View</h3></div></div></div><p>The tutorial project <span class="propername">World Space</span> demonstrates
                the use of a mobile camera in a world-space scene.</p><div class="figure"><a name="d0e6940"></a><p class="title"><b>Figure&nbsp;7.2.&nbsp;World Space Scene</b></p><div class="figure-contents"><div class="mediaobject"><img src="World%20Scene.png" alt="World Space Scene"></div></div></div><br class="figure-break"><p>The controls for this tutorial are as follows:</p><div class="table"><a name="d0e6948"></a><p class="title"><b>Table&nbsp;7.1.&nbsp;World Space Controls</b></p><div class="table-contents"><table summary="World Space Controls" border="1"><colgroup><col><col><col></colgroup><thead><tr><th>Function</th><th>Increase/Left</th><th>Decrease/Right</th></tr></thead><tbody><tr><td>Move camera target up/down</td><td><span class="keycap"><strong>E</strong></span></td><td><span class="keycap"><strong>Q</strong></span></td></tr><tr><td>Move camera target horizontally</td><td><span class="keycap"><strong>A</strong></span></td><td><span class="keycap"><strong>D</strong></span></td></tr><tr><td>Move camera target vertically</td><td><span class="keycap"><strong>W</strong></span></td><td><span class="keycap"><strong>S</strong></span></td></tr><tr><td>Rotate camera horizontally around target</td><td><span class="keycap"><strong>L</strong></span></td><td><span class="keycap"><strong>J</strong></span></td></tr><tr><td>Rotate camera vertically around target</td><td><span class="keycap"><strong>I</strong></span></td><td><span class="keycap"><strong>K</strong></span></td></tr><tr><td>Move camera towards/away from target</td><td><span class="keycap"><strong>U</strong></span></td><td><span class="keycap"><strong>O</strong></span></td></tr></tbody></table></div></div><br class="table-break"><p>In addition, if you hold down the shift key while pressing any of these keys, then
                the affected control will be much slower. This allows for more precision movements.
                The spacebar will toggle the appearance of an object indicating the position of the
                camera point.</p><p>This world is more complicated than anything we've seen up until now. There are a
                lot of objects being rendered, and most of them are composed out of multiple
                objects.</p><p>This tutorial is the first to incorporate some of the features of the Unofficial
                OpenGL SDK. Specifically, it uses the GL Util library's
                    <code class="classname">glutil::MatrixStack</code> class, which implements a matrix
                stack very much like we saw in the last tutorial. The main difference is that we do
                not use explicit push/pop functions. To push a matrix onto the stack, we instead use
                a stack object, <code class="classname">glutil::PushStack</code>. The constructor pushes the
                matrix and the destructor automatically pops it. This way, we can never stack
                overflow or underflow.<sup>[<a name="d0e7030" href="#ftn.d0e7030" class="footnote">4</a>]</sup></p><p>The tutorial also is the first to use the Framework's mesh class:
                    <code class="classname">Framework::Mesh</code>. It implements mesh loading from an
                XML-based file format. We will discuss some of the functioning of this class in
                detail in the next section. For now, let us say that this class's
                    <code class="function">Mesh::Render</code> function is equivalent to binding a vertex
                array object, rendering with one or more <code class="function">glDraw*</code> calls, and
                then unbinding the VAO. It expects a suitable program object to be bound to the
                context.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e7050"></a>Multiple Programs</h3></div></div></div><p>Speaking of suitable program objects, this will be the first tutorial that uses
                more than one program object. This is the perfect time to bring up an important
                issue.</p><p>Separate programs do not share uniform locations. That is, if you call
                    <code class="function">glGetUniformLocation</code> on one program object, it will not
                necessarily return the same value from a different program object. This is
                regardless of any other circumstance. You can declare the uniforms with the same
                name, with the same types, in the same order, but OpenGL will not
                    <span class="emphasis"><em>guarantee</em></span> that you get the same uniform locations. It
                does not even guarantee that you get the same uniform locations on different
                run-through of the same executable.</p><p>This means that uniform locations are local to a program object. Uniform data is
                also local to an object. For example:</p><div class="example"><a name="d0e7065"></a><p class="title"><b>Example&nbsp;7.1.&nbsp;Window Resizing</b></p><div class="example-contents"><pre class="programlisting"><span class="code-keyword">void</span> reshape (<span class="code-keyword">int</span> w, <span class="code-keyword">int</span> h)
{
    glutil::MatrixStack persMatrix;
    persMatrix.Perspective(<span class="code-number">45.0f</span>, (w / (<span class="code-keyword">float</span>)h), g_fzNear, g_fzFar);
    
    glUseProgram(UniformColor.theProgram);
    glUniformMatrix4fv(UniformColor.cameraToClipMatrixUnif, <span class="code-number">1</span>, GL_FALSE, glm::value_ptr(persMatrix.Top()));
    glUseProgram(ObjectColor.theProgram);
    glUniformMatrix4fv(ObjectColor.cameraToClipMatrixUnif, <span class="code-number">1</span>, GL_FALSE, glm::value_ptr(persMatrix.Top()));
    glUseProgram(UniformColorTint.theProgram);
    glUniformMatrix4fv(UniformColorTint.cameraToClipMatrixUnif, <span class="code-number">1</span>, GL_FALSE, glm::value_ptr(persMatrix.Top()));
    glUseProgram(<span class="code-number">0</span>);
    
    glViewport(<span class="code-number">0</span>, <span class="code-number">0</span>, (GLsizei) w, (GLsizei) h);
    glutPostRedisplay();
}</pre></div></div><br class="example-break"><p>Here's our new function of the window reshaping function, using the
                    <code class="function">MatrixStack::Perspective</code> function to generate the correct
                perspective projection matrix. Notice that we must bind the 3 separate programs and
                individually update each one's uniform for the camera-to-clip matrix.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e7075"></a>Attributes and Programs</h3></div></div></div><p>Our three programs are made from 2 vertex shaders and 3 fragment shaders. The
                differences between these shaders is based on where they get their color information
                from.</p><p>We create three programs. One that expects a per-vertex color and uses that to
                write the fragment color. One that expects a per-vertex color and multiplies that
                with a uniform color to determine the fragment color. And one that does not take a
                per-vertex color; it simply uses the uniform color as the fragment's color. All of
                these do the same positional transformation, which is a series of three matrix
                multiplications:</p><div class="example"><a name="d0e7082"></a><p class="title"><b>Example&nbsp;7.2.&nbsp;Position-only Vertex Shader</b></p><div class="example-contents"><pre class="programlisting">#version <span class="code-number">330</span>

<span class="code-modifier">layout</span>(location = <span class="code-number">0</span>) <span class="code-modifier">in</span> <span class="code-type">vec4</span> position;

<span class="code-modifier">uniform</span> <span class="code-type">mat4</span> cameraToClipMatrix;
<span class="code-modifier">uniform</span> <span class="code-type">mat4</span> worldToCameraMatrix;
<span class="code-modifier">uniform</span> <span class="code-type">mat4</span> modelToWorldMatrix;

<span class="code-type">void</span> main()
{
    <span class="code-type">vec4</span> temp = modelToWorldMatrix * position;
    temp = worldToCameraMatrix * temp;
    gl_Position = cameraToClipMatrix * temp;
}</pre></div></div><br class="example-break"><div class="sidebar"><p class="title"><b>Mismatched Attributes and Programs</b></p><p>You may be wondering what happens if there is a mis-match between the
                    attributes provided by a VAO and the vertex shader inputs. For example, we could
                    use the position-only vertex shader with a mesh that provides attributes 0 and
                    1, with 0 being the position and 1 being the color.</p><p>OpenGL is actually very lenient about this sort of thing. It also goes through
                    some effort to fully define what information the vertex shader gets in the event
                    of a mismatch.</p><p>A VAO can provide attributes that a vertex shader does not use without
                    penalty. Well, there may be a performance penalty for reading unused
                    information, but it will still render correctly.</p><p>If a vertex shader takes attributes that the VAO does not provide, then the
                    value the vertex shader gets will be a vector of (0, 0, 0, 1). If the vertex
                    shader input vector has fewer than 4 elements, then it fills them in in that
                    order. A vec3 input that is not provided by the VAO will be (0, 0, 0).</p><p>Speaking of which, if a VAO provides more components of an attribute vector
                    than the vertex shader expects (the VAO provides 4 elements, but the vertex
                    shader input is a vec2), then the vertex shader input will be filled in as much
                    as it can be. If the reverse is true, if the VAO does not provide enough
                    components of the vector, then the unfilled values are always filled in from the
                    (0, 0, 0, 1) vector.</p></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e7100"></a>Camera of the World</h3></div></div></div><p>The main rendering function implements the world-space and camera code. It begins
                by updating the world-to-camera matrix.</p><div class="example"><a name="d0e7105"></a><p class="title"><b>Example&nbsp;7.3.&nbsp;Upload World to Camera Matrix</b></p><div class="example-contents"><pre class="programlisting"><span class="code-keyword">const</span> glm::vec3 &amp;camPos = ResolveCamPosition();

glutil::MatrixStack camMatrix;
camMatrix.SetMatrix(CalcLookAtMatrix(camPos, g_camTarget, glm::vec3(<span class="code-number">0.0f</span>, <span class="code-number">1.0f</span>, <span class="code-number">0.0f</span>)));

glUseProgram(UniformColor.theProgram);
glUniformMatrix4fv(UniformColor.worldToCameraMatrixUnif, <span class="code-number">1</span>, GL_FALSE, glm::value_ptr(camMatrix.Top()));
glUseProgram(ObjectColor.theProgram);
glUniformMatrix4fv(ObjectColor.worldToCameraMatrixUnif, <span class="code-number">1</span>, GL_FALSE, glm::value_ptr(camMatrix.Top()));
glUseProgram(UniformColorTint.theProgram);
glUniformMatrix4fv(UniformColorTint.worldToCameraMatrixUnif, <span class="code-number">1</span>, GL_FALSE, glm::value_ptr(camMatrix.Top()));
glUseProgram(<span class="code-number">0</span>);</pre></div></div><br class="example-break"><p>The function <code class="function">ResolveCamPosition</code> computes the camera position,
                based on the user's input. <code class="function">CalcLookAtMatrix</code> is the function
                that takes a camera position in the world, a point in the world to look at, and an
                up vector, and uses it to compute the world-to-camera matrix. We will look at that a
                bit later.</p><p>Speaking of which, let's look at how <code class="function">ResolveCamPosition</code>
                works. The basic idea of this camera system is that there is a target point, which
                is mobile. The camera's position is computed relative to this target point, so if
                the target moves, the camera will follow it perfectly.</p><p>To do this, we use a special coordinate system trick. Instead of storing the
                relative position of the camera in a normal coordinate system, we instead use a
                    <em class="glossterm">spherical coordinate system</em>, also known as
                    <em class="glossterm">polar coordinates</em>.</p><p>Previously, we said that a coordinate system was defined by a series of vectors
                and an origin point. This was a useful simplification of the possibilities; this is
                true of any coordinate system that follows the rules of <em class="glossterm">Euclidean
                    geometry</em>. Spherical coordinates (among many others) are
                non-Euclidean. For example, in Euclidean geometry, the sum of the angles of any
                triangle will add up to 180 degrees exactly. This is not true of spherical
                geometries or spherical coordinates. This is because <span class="quote">&#8220;<span class="quote">lines</span>&#8221;</span> in
                spherical geometries are curves when seen relative to Euclidean geometries.</p><p>Spherical coordinates are three dimensional, so they have 3 values. One value,
                commonly given the name <span class="quote">&#8220;<span class="quote">r</span>&#8221;</span> (for radius) represents the distance of the
                coordinate from the center of the coordinate system. This value is on the range [0,
                &#8734;). The second value, called <span class="quote">&#8220;<span class="quote">&#966;</span>&#8221;</span> (phi), represents the angle in the
                elliptical plane. This value extends on the range [0, 360). The third value, called
                    <span class="quote">&#8220;<span class="quote">&#952;</span>&#8221;</span> (theta), represents the angle above and below the elliptical
                plane. This value is on the range [0, 180], where 0 means straight up and 180 means
                straight down.</p><p>This is much easier to see in diagram form:</p><div class="figure"><a name="d0e7152"></a><p class="title"><b>Figure&nbsp;7.3.&nbsp;Spherical Coordinates</b></p><div class="figure-contents"><div class="mediaobject"><img src="Coord_system_SZ_0.svg" alt="Spherical Coordinates"></div></div></div><br class="figure-break"><p>This is a very convenient coordinate system for positioning an object around
                another object, particularly if you want to move along spheres relative to another
                object. The transformation from spherical coordinates back to Euclidean geometric
                coordinates is implemented in <code class="function">ResolveCamPosition.</code></p><div class="example"><a name="d0e7162"></a><p class="title"><b>Example&nbsp;7.4.&nbsp;Spherical to Euclidean Transform</b></p><div class="example-contents"><pre class="programlisting">glm::vec3 ResolveCamPosition()
{
    glutil::MatrixStack tempMat;
    
    <span class="code-keyword">float</span> phi = Framework::DegToRad(g_sphereCamRelPos.x);
    <span class="code-keyword">float</span> theta = Framework::DegToRad(g_sphereCamRelPos.y + <span class="code-number">90.0f</span>);
    
    <span class="code-keyword">float</span> fSinTheta = sinf(theta);
    <span class="code-keyword">float</span> fCosTheta = cosf(theta);
    <span class="code-keyword">float</span> fCosPhi = cosf(phi);
    <span class="code-keyword">float</span> fSinPhi = sinf(phi);
    
    glm::vec3 dirToCamera(fSinTheta * fCosPhi, fCosTheta, fSinTheta * fSinPhi);
    <span class="code-keyword">return</span> (dirToCamera * g_sphereCamRelPos.z) + g_camTarget;
}</pre></div></div><br class="example-break"><p>The global variable <code class="varname">g_sphereCamRelPos</code> contains the spherical
                coordinates. The X value contains &#966;, the Y value contains &#952;, and the Z value is the
                radius.</p><p>The Theta value used in our spherical coordinates is slightly different from the
                usual. Instead of being on the range [0, 180], it is on the range [-90, 90]; this is
                why there is an addition by 90 degrees before computing the Theta angle in
                radians.</p><p>The <code class="varname">dirToCamera</code> is just a direction vector. Only by scaling it
                by the radius (<code class="varname">g_sphereCamRelPos.z</code>) do we get the full
                decomposition from spherical coordinates to Euclidean. Applying the camera target as
                an offset is what keeps the camera's position relative to the target.</p><p>All of the above simply gets us a position for the camera and a location where the
                camera is looking. The matrix is computed by feeding these values into
                    <code class="function">CalcLookAtMatrix</code>. It takes a position for the camera, a
                point in the world that the camera should be looking in, and a direction in
                world-space that should be considered <span class="quote">&#8220;<span class="quote">up</span>&#8221;</span> based on where the camera is
                looking.</p><p>The implementation of this function is non-trivial. We will not go into detail
                explaining how it works, as it involves a lot of complex math concepts that have not
                been introduced. Using the function is is much easier than understanding how it
                works. Even so, there is one major caveat with this function (and any function of
                the like).</p><p>It is very important that the <span class="quote">&#8220;<span class="quote">up</span>&#8221;</span> direction is not along the same
                line as the direction from the camera position to the look at target. If up is very
                close to that direction then the generated matrix is no longer valid and unpleasant
                things will happen.</p><p>Since it does not make physical sense for <span class="quote">&#8220;<span class="quote">up</span>&#8221;</span> to be directly behind
                or in front of the viewer, it makes a degree of sense that this would likewise
                produce a nonsensical matrix. This problem usually crops up in camera systems like
                the one devised here, where the camera is facing a certain point and is rotating
                around that point, without rotating the up direction at the same time. In the case
                of this code, the up/down angle is clamped to never get high enough to cause a
                problem.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e7202"></a>World Rendering</h3></div></div></div><p>Once the camera matrix is computed, it is farmed out to each of the programs.
                After that, rendering is pretty simple.</p><p>The meshes we have loaded for this tutorial are unit sized. That is, they are one
                unit across in their major axes. They also are usually centered at the origin in
                their local coordinate system. This make it easy to scale them to arbitrary sizes
                for any particular use.</p><p>The ground is based on the unit plane mesh. This is just a square with the sides
                being unit length. This is rendered by the following code:</p><div class="example"><a name="d0e7211"></a><p class="title"><b>Example&nbsp;7.5.&nbsp;Draw the Ground</b></p><div class="example-contents"><pre class="programlisting">glutil::PushStack push(modelMatrix);

modelMatrix.Scale(glm::vec3(<span class="code-number">100.0f</span>, <span class="code-number">1.0f</span>, <span class="code-number">100.0f</span>));

glUseProgram(UniformColor.theProgram);
glUniformMatrix4fv(UniformColor.modelToWorldMatrixUnif, <span class="code-number">1</span>, GL_FALSE, glm::value_ptr(modelMatrix.Top()));
glUniform4f(UniformColor.baseColorUnif, <span class="code-number">0.302f</span>, <span class="code-number">0.416f</span>, <span class="code-number">0.0589f</span>, <span class="code-number">1.0f</span>);
g_pPlaneMesh-&gt;Render();
glUseProgram(<span class="code-number">0</span>);</pre></div></div><br class="example-break"><p>The unit plane mesh has no color attribute, so we use the
                    <code class="varname">UniformColor</code> program. We apply a scale matrix to the model
                stack, so that the 1x1 plane becomes 100x100 in size. After setting the color, the
                plane is rendered.</p><p>All of the trees are drawn from the <code class="function">DrawForest</code>
                function.</p><div class="example"><a name="d0e7226"></a><p class="title"><b>Example&nbsp;7.6.&nbsp;DrawForest Function</b></p><div class="example-contents"><pre class="programlisting"><span class="code-keyword">void</span> DrawForest(glutil::MatrixStack &amp;modelMatrix)
{
    <span class="code-keyword">for</span>(<span class="code-keyword">int</span> iTree = <span class="code-number">0</span>; iTree &lt; ARRAY_COUNT(g_forest); iTree++)
    {
        <span class="code-keyword">const</span> TreeData &amp;currTree = g_forest[iTree];
        
        glutil::PushStack push(modelMatrix);
        modelMatrix.Translate(glm::vec3(currTree.fXPos, <span class="code-number">0.0f</span>, currTree.fZPos));
        DrawTree(modelMatrix, currTree.fTrunkHeight, currTree.fConeHeight);
    }
}</pre></div></div><br class="example-break"><p>This function iterates over a large table and draws a tree for each element in
                that table. The table entries determine where in world space the tree is drawn and
                how tall it is. The location is stored as a translation in the matrix stack (after
                pushing), and the tree attributes are passed to the <code class="function">DrawTree</code>
                function to render.</p><p>The Parthenon is drawn from the <code class="function">DrawParthenon</code> function. Since
                this draw function, like <code class="function">DrawTree</code>, expects the matrix stack to
                transform it to its world-space position, the first step we see is applying a
                translation matrix to the stack.</p><div class="example"><a name="d0e7244"></a><p class="title"><b>Example&nbsp;7.7.&nbsp;Call to DrawParthenon</b></p><div class="example-contents"><pre class="programlisting">glutil::PushStack push(modelMatrix);
modelMatrix.Translate(glm::vec3(<span class="code-number">20.0f</span>, <span class="code-number">0.0f</span>, -<span class="code-number">10.0f</span>));

DrawParthenon(modelMatrix);</pre></div></div><br class="example-break"><p>The actual <code class="function">DrawParthenon</code> function is pretty simple. It uses
                    <code class="function">DrawColumn</code> to draw all of the columns at the various
                locations around the building. It draws scaled cubes for the base and ceiling, and
                uses the colored version of the cube for the headpiece at the front and the interior
                of the building. Columns are scaled cubes and cylinders.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e7257"></a>Non-World Rendering</h3></div></div></div><p>The last part of the <code class="function">display</code> function is more interesting.
                Pressing the <span class="keycap"><strong>Spacebar</strong></span> toggles the drawing of a representation of
                the camera target point. Here is how it gets drawn:</p><div class="example"><a name="d0e7268"></a><p class="title"><b>Example&nbsp;7.8.&nbsp;Draw Camera Target</b></p><div class="example-contents"><pre class="programlisting">glDisable(GL_DEPTH_TEST);
glm::mat4 idenity(<span class="code-number">1.0f</span>);

glutil::PushStack push(modelMatrix);

glm::vec3 cameraAimVec = g_camTarget - camPos;
modelMatrix.Translate(<span class="code-number">0.0f</span>, <span class="code-number">0.0</span>, -glm::length(cameraAimVec));
modelMatrix.Scale(<span class="code-number">1.0f</span>, <span class="code-number">1.0f</span>, <span class="code-number">1.0f</span>);

glUseProgram(ObjectColor.theProgram);
glUniformMatrix4fv(ObjectColor.modelToWorldMatrixUnif, <span class="code-number">1</span>, GL_FALSE,
    glm::value_ptr(modelMatrix.Top()));
glUniformMatrix4fv(ObjectColor.worldToCameraMatrixUnif, <span class="code-number">1</span>, GL_FALSE,
    glm::value_ptr(idenity));
g_pCubeColorMesh-&gt;Render();
glUseProgram(<span class="code-number">0</span>);
glEnable(GL_DEPTH_TEST);</pre></div></div><br class="example-break"><p>The first thing that happens is that the depth test is turned off. This means that
                the camera target point will always be seen, no matter where it is. So if you move
                the target point inside the building or a tree, you will still see it. This is a
                useful technique for UI-type objects like this.</p><p>The next important thing is that the world-to-camera matrix is set to identity.
                This means that the model-to-world matrix functions as a model-to-camera matrix. We
                are going back to positioning objects in front of the camera, which is what we
                actually want. The cube is translated down the -Z axis, which positions it directly
                in front of the camera. It positions the square at the same distance from the camera
                as the camera would be from the target point.</p><p>For the last few tutorials, we have been building up a transformation framework
                and hierarchy. Model space to world space to camera space to clip space. But the
                important thing to remember is that this framework is only useful to you if it does
                what you want. If you need to position an object directly in front of the camera,
                then simply remove world space from the equation entirely and deal directly with
                camera space.</p><p>We could even turn the depth test back on, and the camera target would interact
                correctly with the rest of the world. It is a part of the world, even though it
                seems like it goes through a different transform pipe.</p><p>Indeed, you could render part of a scene with one perspective matrix and part with
                another. This is a common technique for first-person shooter games. The main world
                is rendered with one perspective, and the part of the first-person character that is
                visible is rendered with another matrix.</p><p>Do not get so caught up in <span class="quote">&#8220;<span class="quote">the way things ought to be done</span>&#8221;</span> that you
                forget what you could have done if you broke free of the framework. Never hold so
                tightly to one way of doing something that it prevents you from seeing how to do
                something you need to much easier. For example, we could have applied the reverse of
                the camera matrix to the model-to-world matrix. Or we could just get rid of that
                matrix altogether and make everything work very easily and simply.</p></div></div><div class="footnotes"><br><hr width="100" align="left"><div class="footnote"><p><sup>[<a name="ftn.d0e7030" href="#d0e7030" class="para">4</a>] </sup>This technique, using constructors and destructors to do this kind of
                        scope-bounded work, is called Resource Acquisition Is Initialization
                            (<acronym class="acronym">RAII</acronym>). It is a common C++ resource management
                        technique. You can find more information about it <a class="link" href="http://www.hackcraft.net/raii/" target="_top">online</a>. If you are
                        unfamiliar with it, I suggest you become familiar with it.</p></div></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="Tut06 Glossary.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="Positioning.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="Tut07 Primitive Drawing.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Glossary&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="../index.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;Primitive Drawing</td></tr></table></div></body></html>