<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <meta http-equiv="X-UA-Compatible" content="IE=Edge"><title>Pointing Projections</title><link rel="stylesheet" href="chunked.css" type="text/css"><meta name="generator" content="DocBook XSL-NS Stylesheets V1.75.2"><link rel="home" href="../index.html" title="Learning Modern 3D Graphics Programming"><link rel="up" href="Tutorial 17.html" title="Chapter&nbsp;17.&nbsp;Spotlight on Textures"><link rel="prev" href="Tut17 Projective Texture.html" title="Projective Texture"><link rel="next" href="Tut17 In Review.html" title="In Review"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">Pointing Projections</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="Tut17 Projective Texture.html">Prev</a>&nbsp;</td><th width="60%" align="center">Chapter&nbsp;17.&nbsp;Spotlight on Textures</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="Tut17 In Review.html">Next</a></td></tr></table><hr></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e16282"></a>Pointing Projections</h2></div></div></div><p>Spotlights represent a light that has position, direction, and perhaps an FOV and some
            kind of aspect ratio. Through projective texturing, we can make spotlights that have
            arbitrary light intensities, rather than relying on uniform values or shader functions
            to compute light intensity. That is all well and good for spotlights, but there are
            other forms of light that might want varying intensities.</p><p>It doesn't really make sense to vary the light intensity from a directional light.
            After all, the while point of directional lights is that they are infinitely far away,
            so all of the light from them is uniform, in both intensity and direction.</p><p>Varying the intensity of a point light is a more reasonable possibility. We can vary
            the point light's intensity based on one of two possible parameters: the position of the
            light and the direction from the light towards a point in the scene. The latter seems
            far more useful; it represents a light that may cast more or less brightly in different
            directions.</p><p>To do this, what we need is a texture that we can effectively access via a direction.
            While there are ways to convert a 3D vector direction into a 2D texture coordinate, we
            will not use any of them. We will instead use a special texture type creates
            specifically for exactly this sort of thing.</p><p>The common term for this kind of texture is <em class="glossterm">cube map</em>, even
            though it is a texture rather than a mapping of a texture. A cube map texture is a
            texture where every mipmap level is 6 2D images, not merely one. Each of the 6 images
            represents one of the 6 faces of a cube. The texture coordinates for a cube map are a 3D
            vector direction; the texture sampling hardware selects which face to sample from and
            which texel to pick based on the direction.</p><p>It is important to know how the 6 faces of the cube map fit together. OpenGL defines
            the 6 faces based on the X, Y, and Z axes, in the positive and negative directions. This
            diagram explains the orientation of the S and T coordinate axes of each of the faces,
            relative to the direction of the faces in the cube.</p><div class="figure"><a name="d0e16301"></a><p class="title"><b>Figure&nbsp;17.9.&nbsp;Cube Map Face Orientation</b></p><div class="figure-contents"><div class="mediaobject"><img src="CubeMapAxes.svg" alt="Cube Map Face Orientation"></div></div></div><br class="figure-break"><p>This information is vital for knowing how to construct the various faces of a cube
            map.</p><p>To use a cube map to specify the light intensity changes for a point light, we simply
            need to do the following. First, we get the direction from the light to the surface
            point of interest. Then we use that direction to sample from the cube map. From there,
            everything is normal.</p><p>The issue is getting the direction from the light to the surface point. Before, a
            point light had no orientation, and this made sense. It cast light uniformly in all
            directions, so even if it had an orientation, you would never be able to tell it was
            there. Now that our light intensity can vary, the point light now needs to be able to
            orient the cube map.</p><p>The easiest way to handle this is a simple transformation trick. The position and
            orientation of the light represents a space. If we transform the position of objects
            into that space, then the direction from the light can easily be obtained. The light's
            position relative to itself is zero, after all. So we need to transform positions from
            some space into the light's space. We will see exactly how this is done
            momentarily.</p><p>Cube map point lights are implemented in the <span class="propername">Cube Point
                Light</span> project. This puts a fixed point light using a cube map in the middle
            of the scene. The orientation of the light can be changed with the right mouse
            button.</p><div class="figure"><a name="d0e16320"></a><p class="title"><b>Figure&nbsp;17.10.&nbsp;Cube Point Light</b></p><div class="figure-contents"><div class="mediaobject"><img src="Cube%20Point%20Light.png" alt="Cube Point Light"></div></div></div><br class="figure-break"><p>This cube texture has various different light arrangements on the different sides. One
            side even has green text on it. As before, you can use the <span class="keycap"><strong>G</strong></span> key to
            toggle the non-cube map lights off.</p><p>Pressing the <span class="keycap"><strong>2</strong></span> key switches to a texture that looks somewhat
            resembles a planetarium show. Pressing <span class="keycap"><strong>1</strong></span> switches back to the first
            texture.</p><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e16339"></a>Cube Texture Loading</h3></div></div></div><p>We have seen how 2D textures get loaded over the course of 3 tutorials now, so we
                use GL Image's functions for creating a texture directly from <span class="type">ImageSet</span>.
                Cube map textures require special handling, so let's look at this now.</p><div class="example"><a name="d0e16347"></a><p class="title"><b>Example&nbsp;17.8.&nbsp;Cube Texture Loading</b></p><div class="example-contents"><pre class="programlisting">std::string filename(Framework::FindFileOrThrow(g_texDefs[tex].filename));
std::auto_ptr&lt;glimg::ImageSet&gt; pImageSet(glimg::loaders::dds::LoadFromFile(filename.c_str()));

glBindTexture(GL_TEXTURE_CUBE_MAP, g_lightTextures[tex]);
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_BASE_LEVEL, <span class="code-number">0</span>);
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MAX_LEVEL, <span class="code-number">0</span>);

glimg::Dimensions dims = pImageSet-&gt;GetDimensions();
GLenum imageFormat = (GLenum)glimg::GetInternalFormat(pImageSet-&gt;GetFormat(), <span class="code-number">0</span>);

<span class="code-keyword">for</span>(<span class="code-keyword">int</span> face = <span class="code-number">0</span>; face &lt; <span class="code-number">6</span>; ++face)
{
    glimg::SingleImage img = pImageSet-&gt;GetImage(<span class="code-number">0</span>, <span class="code-number">0</span>, face);
    glCompressedTexImage2D(GL_TEXTURE_CUBE_MAP_POSITIVE_X + face,
        <span class="code-number">0</span>, imageFormat, dims.width, dims.height, <span class="code-number">0</span>,
        img.GetImageByteSize(), img.GetImageData());
}

glBindTexture(GL_TEXTURE_CUBE_MAP, <span class="code-number">0</span>);</pre></div></div><br class="example-break"><p>The DDS format is one of the few image file formats that can actually store all of
                the faces of a cube map. Similarly, the <span class="type">glimg::ImageSet</span> class can store
                cube map faces.</p><p>The first step after loading the cube map faces is to bind the texture to the
                    <code class="literal">GL_TEXTURE_CUBE_MAP</code> texture binding target. Since this cube
                map is not mipmapped (yes, cube maps can have mipmaps), we set the base and max
                mipmap levels to zero. The call to <code class="function">glimg::GetInternalFormat</code> is
                used to allow GL Image to tell us the OpenGL image format that corresponds to the
                format of the loaded texture data.</p><p>From there, we loop over the 6 faces of the texture, get the
                    <span class="type">SingleImage</span> for that face, and load each face into the OpenGL
                texture. For the moment, pretend the call to
                    <code class="function">glCompressedTexImage2D</code> is a call to
                    <code class="function">glTexImage2D</code>; they do similar things, but the final few
                parameters are different. It may seem odd to call a TexImage2D function when we are
                uploading to a cube map texture. After all, a cube map texture is a completely
                different texture type from 2D textures.</p><p>However, the <span class="quote">&#8220;<span class="quote">TexImage</span>&#8221;</span> family of functions specify the
                dimensionality of the image data they are allocating an uploading, not the specific
                texture type. Since a cube map is simply 6 sets of 2D image images, it uses the
                    <span class="quote">&#8220;<span class="quote">TexImage2D</span>&#8221;</span> functions to allocate the faces and mipmaps. Which
                face is specified by the first parameter.</p><p>OpenGL has six enumerators of the form
                    <code class="literal">GL_TEXTURE_CUBE_MAP_POSITIVE/NEGATIVE_X/Y/Z</code>. These
                enumerators are ordered, starting with positive X, so we can loop through all of
                them by adding the numbers [0, 5] to the positive X enumerator. That is what we do
                above. The order of these enumerators is:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>POSITIVE_X</p></li><li class="listitem"><p>NEGATIVE_X</p></li><li class="listitem"><p>POSITIVE_Y</p></li><li class="listitem"><p>NEGATIVE_Y</p></li><li class="listitem"><p>POSITIVE_Z</p></li><li class="listitem"><p>NEGATIVE_Z</p></li></ol></div><p>This mirrors the order that the <span class="type">ImageSet</span> stores them in (and DDS
                files, for that matter).</p><p>The samplers for cube map textures also needs some adjustment:</p><pre class="programlisting">glSamplerParameteri(g_samplers[<span class="code-number">0</span>], GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
glSamplerParameteri(g_samplers[<span class="code-number">0</span>], GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
glSamplerParameteri(g_samplers[<span class="code-number">0</span>], GL_TEXTURE_WRAP_R, GL_CLAMP_TO_EDGE);</pre><p>Cube maps take 3D texture coordinates, so wrap modes must be specified for each of
                the three dimensions of texture coordinates. Since this cube map has no mipmaps, the
                filtering is simply set to <code class="literal">GL_LINEAR</code>.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e16422"></a>Texture Compression</h3></div></div></div><p>Now we will take a look at why we are using
                    <code class="function">glCompressedTexImage2D</code>. And that requires a discussion of
                image formats and sizes.</p><p>Images take up a lot of memory. And while disk space and even main memory are
                fairly generous these days, GPU memory is always at a premium. Especially if you
                have lots of textures and those textures are quite large. The smaller that texture
                data can be, the more and larger textures you can have in a complex scene.</p><p>The first stop for making this data smaller is to use a smaller image format. For
                example, the standard RGB color format stores each channel as an 8-bit unsigned
                integer. This is usually padded out to make it 4-byte aligned, or a fourth component
                (alpha) is added, making for an RGBA color. That's 32-bits per texel, which is what
                    <code class="literal">GL_RGBA8</code> specifies. A first pass for making this data smaller
                is to store it with fewer bits. OpenGL provides <code class="literal">GL_RGB565</code> for
                those who do not need the fourth component, or <code class="literal">GL_RGBA4</code> for those
                who do. Both of these use 16-bits per texel.</p><p>They both also can produce unpleasant visual artifacts for the textures. Plus,
                OpenGL does not allow such textures to be in the sRGB colorspace; there is no
                    <code class="literal">GL_SRGB565</code> format.</p><p>For files, this is a solved problem. There are a number of traditional compressed
                image formats: PNG, JPEG, GIF, etc. Some are lossless, meaning that the exact input
                image can be reconstructed. Others are lossy, which means that only an approximation
                of the image can be returned. Either way, these all formats have their benefits and
                downsides. But they are all better, in terms of visual quality and space storage,
                than using 16-bit per texel image formats.</p><p>They also have one other thing in common: they are absolutely terrible for
                    <span class="emphasis"><em>textures</em></span>, in terms of GPU hardware. These formats are
                designed to be decompressed all at once; you decompress the entire image when you
                want to see it. GPUs don't want to do that. GPUs generally access textures in
                pieces; they access certain sections of a mipmap level, then access other sections,
                etc. GPUs gain their performance by being incredibly parallel: multiple different
                invocations of fragment shaders can be running simultaneously. All of them can be
                accessing different textures and so forth.</p><p>Stopping that processes to decompress a 50KB PNG would pretty much destroy
                rendering performance entirely. These formats may be fine for storing files on disk.
                But they are simply not good formats for being stored compressed in graphics
                memory.</p><p>Instead, there are special formats designed specifically for compressing textures.
                These <em class="glossterm">texture compression</em> formats are designed specifically
                to be friendly for texture accesses. It is easy to find the exact piece of memory
                that stores the data for a specific texel. It takes no more than 64 bits of data to
                decompress any one texel. And so forth. These all combine to make texture
                compression formats useful for saving graphics card memory, while maintaining
                reasonable image quality.</p><p>The regular <code class="function">glTexImage2D</code> function is not capable of directly
                uploading compressed texture data. The pixel transfer information, the last three
                parameters of <code class="function">glTexImage2D</code>, is simply not appropriate for
                dealing with compressed texture data. Therefore, OpenGL uses a different function
                for uploading texture data that is already compressed.</p><pre class="programlisting">glCompressedTexImage2D(GL_TEXTURE_CUBE_MAP_POSITIVE_X + face,
    <span class="code-number">0</span>, imageFormat, dims.width, dims.height, <span class="code-number">0</span>,
    img.GetImageByteSize(), img.GetImageData());</pre><p>Instead of taking OpenGL enums that define what the format of the compressed data
                is, <code class="function">glCompressedTexImage2D</code>'s last two parameters are very
                simple. They specify how big the compressed image data is in bytes and provide a
                pointer to that image data. That is because
                    <code class="function">glCompressedTexImage2D</code> does not allow for format
                conversion; the format of the pixel data passed to it must exactly match what the
                image format says it is. This also means that the
                    <code class="literal">GL_UNPACK_ALIGNMENT</code> has no effect on compressed texture
                uploads.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e16483"></a>Cube Texture Space</h3></div></div></div><p>Creating the cube map texture was just the first step. The next step is to do the
                necessary transformations. Recall that the goal is to transform the vertex positions
                into the space of the texture, defined relative to world space by a position and
                orientation. However, we ran into a problem previously, because the scene graph only
                provides a model-to-camera transformation matrix.</p><p>This problem still exists, and we will solve it in exactly the same way. We will
                generate a matrix that goes from camera space to our cube map light's space.</p><div class="example"><a name="d0e16490"></a><p class="title"><b>Example&nbsp;17.9.&nbsp;View Camera to Light Cube Texture</b></p><div class="example-contents"><pre class="programlisting">glutil::MatrixStack lightProjStack;
lightProjStack.ApplyMatrix(glm::inverse(lightView));
lightProjStack.ApplyMatrix(glm::inverse(cameraMatrix));

g_lightProjMatBinder.SetValue(lightProjStack.Top());

glm::vec4 worldLightPos = lightView[<span class="code-number">3</span>];
glm::vec3 lightPos = glm::vec3(cameraMatrix * worldLightPos);

g_camLightPosBinder.SetValue(lightPos);</pre></div></div><br class="example-break"><p>This code is rather simpler than the prior time. Again reading bottom up, we
                transform by the inverse of the world-to-camera matrix, then we transform by the
                inverse of the light matrix. The <code class="varname">lightView</code> matrix is inverted
                because the matrix is ordinarily designed to go from light space to world space. So
                we invert it to get the world-to-light transform. The light's position in world
                space is taken similarly.</p><p>The vertex shader (cubeLight.vert) is about what you would expect:</p><pre class="programlisting">lightSpacePosition = (cameraToLightProjMatrix * <span class="code-type">vec4</span>(cameraSpacePosition, <span class="code-number">1.0</span>)).xyz;</pre><p>The <code class="varname">lightSpacePosition</code> is output from the vertex shader and
                interpolated. Again we find that this interpolates just fine, so there is no need to
                do this transformation per-fragment.</p><p>The fragment shader code (<code class="filename">cubeLight.frag</code>) is pretty simple.
                First, we have to define our GLSL samplers:</p><pre class="programlisting"><span class="code-modifier">uniform</span> <span class="code-sampler">sampler2D</span> diffuseColorTex;
<span class="code-modifier">uniform</span> <span class="code-sampler">samplerCube</span> lightCubeTex;</pre><p>Because cube maps are a different texture type, they have a different GLSL sampler
                type as well. Attempting to use texture with the one type on a sampler that uses a
                different type results in unpleasantness. It's usually easy enough to keep these
                things straight, but it can be a source of errors or non-rendering.</p><p>The code that fetches from the cube texture is as follows:</p><pre class="programlisting">PerLight currLight;
currLight.cameraSpaceLightPos = <span class="code-type">vec4</span>(cameraSpaceProjLightPos, <span class="code-number">1.0</span>);
	
<span class="code-type">vec3</span> dirFromLight = <span class="code-function">normalize</span>(lightSpacePosition);
currLight.lightIntensity =
    <span class="code-function">texture</span>(lightCubeTex, dirFromLight) * <span class="code-number">6.0f</span>;</pre><p>We simply normalize the light-space position, since the cube map's space has the
                light position at the origin. We then use the <code class="function">texture</code> to access
                the cubemap, the same one we used for 2D textures. This is possible because GLSL
                overloads the <code class="function">texture</code> based on the type of sampler. So when
                    <code class="function">texture</code> is passed a <span class="type">samplerCube</span>, it expects a
                    <span class="type">vec3</span> texture coordinate.</p></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="Tut17 Projective Texture.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="Tutorial 17.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="Tut17 In Review.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Projective Texture&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="../index.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;In Review</td></tr></table></div></body></html>