<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <meta http-equiv="X-UA-Compatible" content="IE=Edge"><title>In Review</title><link rel="stylesheet" href="chunked.css" type="text/css"><meta name="generator" content="DocBook XSL-NS Stylesheets V1.75.2"><link rel="home" href="../index.html" title="Learning Modern 3D Graphics Programming"><link rel="up" href="Tutorial 17.html" title="Chapter&nbsp;17.&nbsp;Spotlight on Textures"><link rel="prev" href="Tut17 Pointing Projections.html" title="Pointing Projections"><link rel="next" href="Tut17 Glossary.html" title="Glossary"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">In Review</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="Tut17 Pointing Projections.html">Prev</a>&nbsp;</td><th width="60%" align="center">Chapter&nbsp;17.&nbsp;Spotlight on Textures</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="Tut17 Glossary.html">Next</a></td></tr></table><hr></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e16539"></a>In Review</h2></div></div></div><p>In this tutorial, you have learned the following:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Vertex positions can be further manipulated after a perspective projection.
                    Thus the perspective transform is not special. The shape of objects in
                    post-projective space can be unusual and unexpected.</p></li><li class="listitem"><p>Textures can be projected onto meshes. This is done by transforming those
                    meshes into the space of the texture, which is equivalent to transforming the
                    texture into the space of the meshes. The transform is governed by its own
                    camera matrix, as well as a projection matrix and a post-projective transform
                    that transforms it into the [0, 1] range of the texture.</p></li><li class="listitem"><p>Cube maps are textures that have 6 face images for every mipmap level. The 6
                    faces are arranged in a cube. Texture coordinates are effectively directions of
                    a vector centered within the cube. Thus a cube map can provide a varying value
                    based on a direction in space.</p></li></ul></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e16555"></a>Further Study</h3></div></div></div><p>Try doing these things with the given programs.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>In the spotlight project, change the projection texture coordinate from a
                        full 4D coordinate to a 2D. Do this by performing the divide-by-W step
                        directly in the vertex shader, and simply pass the ST coordinates to the
                        fragment shader. Just use <code class="function">texture</code> instead of
                            <code class="function">textureProj</code> in the fragment shader. See how that
                        affects things. Also, try doing the perspective divide in the fragment
                        shader and see how this differs from doing it in the vertex shader.</p></li><li class="listitem"><p>In the spotlight project, change the interpolation style from
                            <code class="literal">smooth</code> to <code class="literal">noperspective</code>. See how
                        non-perspective-correct interpolation changes the projection.</p></li><li class="listitem"><p>Instead of using a projective texture, build a lighting system for spot
                        lights entirely within the shader. It should have a maximum angle; the
                        larger the angle, the wider the spotlight. It should also have an inner
                        angle that is smaller than the maximum angle. This the the point where the
                        light starts falling off. At the maximum angle, the light intensity goes to
                        zero; at the minimum angle, the light intensity is full. The key here is
                        remembering that the dot product between the spotlight's direction and the
                        direction from the surface to the light is the cosine of the angle between
                        the two vectors. The <code class="function">acos</code> function can be used to
                        compute the angle (in radians) from the cosine.</p></li></ul></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e16585"></a>Further Research</h3></div></div></div><p>Cube maps are fairly old technology. The version used in GPUs today derive from
                the Renderman standard and earlier works. However, before hardware that allowed
                cubemaps became widely available, there were alternative techniques that were used
                to achieve similar effects.</p><p>The basic idea behind all of these is to transform a 3D vector direction into a 2D
                texture coordinate. Note that converting a 3D direction into a 2D plane is a problem
                that was encountered long before computer graphics. It is effectively the global
                mapping problem: how you create a 2D map of a 3D spherical surface. All of these
                techniques introduce some distance distortion into the 2D map. Some distortion is
                more acceptable in certain circumstances than others.</p><p>One of the more common pre-cube map techniques was sphere mapping. This required a
                very heavily distorted 2D texture, so the results left something to be desired. But
                the 3D-to-2D computations were simple enough to be encoded into early graphics
                hardware, or performed quickly on the CPU, so it was acceptable as a stop-gap. Other
                techniques, such as dual paraboloid mapping, were also used. The latter used a pair
                of textures, so they ate up more resources. But they required less heavy distortions
                of the texture, so in some cases, they were a better tradeoff.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e16594"></a>OpenGL Functions of Note</h3></div></div></div><div class="glosslist"><dl><dt>glCompressedTexImage2D</dt><dd><p>Allocates a 2D image of the given size and mipmap for the current
                            texture, using the given compressed image format, and uploads compressed
                            pixel data. The pixel data must exactly match the format of the data
                            defined by the compressed image format.</p></dd></dl></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e16604"></a>GLSL Functions of Note</h3></div></div></div><div class="funcsynopsis"><table border="0" summary="Function synopsis" cellspacing="0" cellpadding="0" class="funcprototype-table"><tr><td><code class="funcdef">vec4 <b class="fsfunc">textureProj</b>(</code></td><td>sampler <var class="pdparam">texSampler</var>, </td></tr><tr><td>&nbsp;</td><td>vec texCoord<code>)</code>;</td></tr></table><div class="funcprototype-spacer">&nbsp;</div></div><p>Accesses the texture associated with <em class="parameter"><code>texSampler</code></em>, using
                post-projective texture coordinates specified by <em class="parameter"><code>texCoord</code></em>.
                The <span class="type">sampler</span> type can be many of the sampler types, but not
                    <span class="type">samplerCube</span>, among a few others. The texture coordinates are in
                homogeneous space, so they have one more components than the number of dimensions of
                the texture. Thus, the number of components in <em class="parameter"><code>texCoord</code></em> for a
                sampler of type <span class="type">sampler1D</span> is <span class="type">vec2</span>. For
                    <span class="type">sampler2D</span>, it is <span class="type">vec3</span>.</p></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="Tut17 Pointing Projections.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="Tutorial 17.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="Tut17 Glossary.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Pointing Projections&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="../index.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;Glossary</td></tr></table></div></body></html>