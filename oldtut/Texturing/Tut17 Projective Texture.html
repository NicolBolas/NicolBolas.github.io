<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <meta http-equiv="X-UA-Compatible" content="IE=Edge"><title>Projective Texture</title><link rel="stylesheet" href="chunked.css" type="text/css"><meta name="generator" content="DocBook XSL-NS Stylesheets V1.75.2"><link rel="home" href="../index.html" title="Learning Modern 3D Graphics Programming"><link rel="up" href="Tutorial 17.html" title="Chapter&nbsp;17.&nbsp;Spotlight on Textures"><link rel="prev" href="Tutorial 17.html" title="Chapter&nbsp;17.&nbsp;Spotlight on Textures"><link rel="next" href="Tut17 Pointing Projections.html" title="Pointing Projections"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">Projective Texture</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="Tutorial 17.html">Prev</a>&nbsp;</td><th width="60%" align="center">Chapter&nbsp;17.&nbsp;Spotlight on Textures</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="Tut17 Pointing Projections.html">Next</a></td></tr></table><hr></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e16043"></a>Projective Texture</h2></div></div></div><p>In order to create our flashlight effect, we need to do something called
                <em class="glossterm">projective texturing</em>. Projective texturing is a special form
            of texture mapping. It is a way of generating texture coordinates for a texture, such
            that it appears that the texture is being projected onto a scene, in much the same way
            that a film projector projects light. Therefore, we need to do two things: implement
            projective texturing, and then use the value we sample from the projected texture as the
            light intensity.</p><p>The key to understanding projected texturing is to think backwards, compared to the
            visual effect we are trying to achieve. We want to take a 2D texture and make it look
            like it is projected onto the scene. To do this, we therefore do the opposite: we
            project the <span class="emphasis"><em>scene</em></span> onto the 2D texture. We want to take the vertex
            positions of every object in the scene and project them into the space of the
            texture.</p><p>Since this is a perspective projection operation, and it involves transforming vertex
            positions, naturally we need a matrix. This is math we already know: we have vertex
            positions in model space. We transform them to a camera space, one that is different
            from the one we use to view the scene. Then we use a perspective projection matrix to
            transform them to clip-space; both the matrix and this clip-space are again different
            spaces from what we use to render the scene. Once perspective divide later, and we're
            done.</p><p>That last part is the small stumbling block. See, after the perspective divide, the
            visible world, the part of the world that is projected onto the texture, lives in a [-1,
            1] sized cube. That is the size of NDC space, though it is again a different NDC space
            from the one we use to render. The problem is that the range of the texture coordinates,
            the space of the 2D texture itself, is [0, 1].</p><p>This is why we needed the prior discussion of post-projective transforms. Because we
            need to do a post-projective transform here: we have to transform the XY coordinates of
            the projected position from [-1, 1] to [0, 1] space. And again, we do not want to have
            to perform the perspective divide ourselves; OpenGL has special functions for texture
            accesses with a divide. Therefore, we encode the translation and scale as a
            post-projective transformation. As previously demonstrated, this is mathematically
            identical to doing the transform after the division.</p><p>This entire process represents a new kind of light. We have seen directional lights,
            which are represented by a light intensity coming from a single direction. And we have
            seen point lights, which are represented by a position in the world which casts light in
            all directions. What we are defining now is typically called a
                <em class="glossterm">spotlight</em>: a light that has a position, direction, and
            oftentimes a few other fields that limit the size and nature of the spot effect.
            Spotlights cast light on a cone-shaped area.</p><p>We implement spotlights via projected textures in the <span class="propername">Projected Light</span> project. This tutorial uses a similar scene to the one
            before, though with slightly different numbers for lighting. The main difference, scene
            wise, is the addition of a textured background box.</p><div class="figure"><a name="d0e16073"></a><p class="title"><b>Figure&nbsp;17.4.&nbsp;Projected Light</b></p><div class="figure-contents"><div class="mediaobject"><img src="Projected%20Light.png" alt="Projected Light"></div></div></div><br class="figure-break"><p>The camera controls work the same way as before. The projected flashlight, represented
            by the red, green, and blue axes, is moved with the IJKL keyboard keys, with O and U
            moving up and down, respectively. The right mouse button rotates the flashlight around;
            the blue line points in the direction of the light. The flashlight's position and
            orientation are built around the camera controls, so it rotates around a point in front
            of the flashlight. It translates relative to its current facing as well. As usual,
            holding down the <span class="keycap"><strong>Shift</strong></span> key will cause the flashlight to move more
            slowly.</p><p>Pressing the <span class="keycap"><strong>G</strong></span> key will toggle all of the regular lighting on and
            off. This makes it easier to see just the light from our projected texture.</p><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e16089"></a>Flashing the Light</h3></div></div></div><p>Let us first look at how we achieve the projected texture effect. We want to take
                the model space positions of the vertices and project them onto the texture.
                However, there is one minor problem: the scene graph system provides a transform
                from model space into the visible camera space. We need a transform to our special
                projected texture camera space, which has a different position and
                orientation.</p><p>We resolve this by being clever. We already have positions in the viewing camera
                space. So we simply start there and construct a matrix from view camera space into
                our texture camera space.</p><div class="example"><a name="d0e16096"></a><p class="title"><b>Example&nbsp;17.6.&nbsp;View Camera to Projected Texture Transform</b></p><div class="example-contents"><pre class="programlisting">glutil::MatrixStack lightProjStack;
<span class="code-comment">//Texture-space transform</span>
lightProjStack.Translate(<span class="code-number">0.5f</span>, <span class="code-number">0.5f</span>, <span class="code-number">0.0f</span>);
lightProjStack.Scale(<span class="code-number">0.5f</span>, <span class="code-number">0.5f</span>, <span class="code-number">1.0f</span>);
<span class="code-comment">//Project. Z-range is irrelevant.</span>
lightProjStack.Perspective(g_lightFOVs[g_currFOVIndex], <span class="code-number">1.0f</span>, <span class="code-number">1.0f</span>, <span class="code-number">100.0f</span>);
<span class="code-comment">//Transform from main camera space to light camera space.</span>
lightProjStack.ApplyMatrix(lightView);
lightProjStack.ApplyMatrix(glm::inverse(cameraMatrix));

g_lightProjMatBinder.SetValue(lightProjStack.Top());</pre></div></div><br class="example-break"><p>Reading the modifications to <code class="varname">lightProjStack</code> in bottom-to-top
                order, we begin by using the inverse of the view camera matrix. This transforms all
                of our vertex positions back to world space, since the view camera matrix is a
                world-to-camera matrix. We then apply the world-to-texture-camera matrix. This is
                followed by a projection matrix, which uses an aspect ratio of 1.0. The last two
                transforms move us from [-1, 1] NDC space to the [0, 1] texture space.</p><p>The zNear and zFar for the projection matrix are almost entirely irrelevant. They
                need to be within the allowed ranges (strictly greater than 0, and zFar must be
                larger than zNear), but the values themselves are meaningless. We will discard the Z
                coordinate entirely later on.</p><p>We use a matrix uniform binder to associate that transformation matrix with all of
                the objects in the scene. This is all we need to do to set up the projection, as far
                as the matrix math is concerned.</p><p>Our vertex shader (<code class="filename">projLight.vert</code>) takes care of things in
                the obvious way:</p><pre class="programlisting">lightProjPosition = cameraToLightProjMatrix * <span class="code-type">vec4</span>(cameraSpacePosition, <span class="code-number">1.0</span>);</pre><p>Note that this line is part of the vertex shader;
                    <code class="varname">lightProjPosition</code> is passed to the fragment shader. One might
                think that the projection would work best in the fragment shader, but doing it
                per-vertex is actually just fine. The only time one would need to do the projection
                per-fragment would be if one was using imposters or was otherwise modifying the
                depth of the fragment. Indeed, because it works per-vertex, projected textures were
                a preferred way of doing cheap lighting in many situations.</p><p>In the fragment shader, <code class="filename">projLight.frag</code>, we want to use the
                projected texture as a light. We have the <code class="function">ComputeLighting</code>
                function in this shader from prior tutorials. All we need to do is make our
                projected light appear to be a regular light.</p><pre class="programlisting">PerLight currLight;
currLight.cameraSpaceLightPos = <span class="code-type">vec4</span>(cameraSpaceProjLightPos, <span class="code-number">1.0</span>);
currLight.lightIntensity =
    <span class="code-function">textureProj</span>(lightProjTex, lightProjPosition.xyw) * <span class="code-number">4.0</span>;

currLight.lightIntensity = lightProjPosition.w &gt; <span class="code-number">0</span> ?
	currLight.lightIntensity : <span class="code-type">vec4</span>(<span class="code-number">0.0</span>);</pre><p>We create a simple structure that we fill in. Later, we pass this structure to
                    <code class="function">ComputeLighting</code>, and it does the usual thing.</p><p>The view camera space position of the projected light is passed in as a uniform.
                It is necessary for our flashlight to properly obey attenuation, as well as to find
                the direction towards the light.</p><p>The next line is where we do the actual texture projection. The
                    <code class="function">textureProj</code> is a texture accessing function that does
                projective texturing. Even though <code class="varname">lightProjTex</code> is a
                    <span class="type">sampler2D</span> (for 2D textures), the texture coordinate has three
                dimensions. All forms of <code class="function">textureProj</code> take one extra texture
                coordinate compared to the regular <code class="function">texture</code> function. This extra
                texture coordinate is divided into the previous one before being used to access the
                texture. Thus, it performs the perspective divide for us.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>Mathematically, there is virtually no difference between using
                        <code class="function">textureProj</code> and doing the divide ourselves and calling
                        <code class="function">texture</code> with the results. While there may not be a
                    mathematical difference, there very well may be a performance difference. There
                    may be specialized hardware that does the division much faster than the
                    general-purpose opcodes in the shader. Then again, there may not. However, using
                        <code class="function">textureProj</code> will certainly be no slower than
                        <code class="function">texture</code> in the general case, so it's still a good
                    idea.</p></div><p>Notice that the value pulled from the texture is scaled by 4.0. This is done
                because the color values stored in the texture are clamped to the [0, 1] range. To
                bring it up to our high dynamic range, we need to scale the intensity
                appropriately.</p><p>The texture being projected is bound to a known texture unit globally; the scene
                graph already associates the projective shader with that texture unit. So there is
                no need to do any special work in the scene graph to make objects use the
                texture.</p><p>The last statement is special. It compares the W component of the interpolated
                position against zero, and sets the light intensity to zero if the W component is
                less than or equal to 0. What is the purpose of this?</p><p>It stops this from happening:</p><div class="figure"><a name="d0e16179"></a><p class="title"><b>Figure&nbsp;17.5.&nbsp;Back Projected Light</b></p><div class="figure-contents"><div class="mediaobject"><img src="LightBackProjection.png" alt="Back Projected Light"></div></div></div><br class="figure-break"><p>The projection math doesn't care what side of the center of projection an object
                is on; it will work either way. And since we do not actually do clipping on our
                texture projection, we need some way to prevent this from happening. We effectively
                need to do some form of clipping.</p><p>Recall that, given the standard projection transform, the W component is the
                negation of the camera-space Z. Since the camera in our camera space is looking down
                the negative Z axis, all positions that are in front of the camera must have a W &gt;
                0. Therefore, if W is less than or equal to 0, then the position is behind the
                camera.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="d0e16189"></a>Spotlight Tricks</h3></div></div></div><p>The size of the flashlight can be changed simply by modifying the field of view in
                the texture projection matrix. Pressing the <span class="keycap"><strong>Y</strong></span> key will increase the
                FOV, and pressing the <span class="keycap"><strong>N</strong></span> key will decrease it. An increase to the
                FOV means that the light is projected over a greater area. At a large FOV, we
                effectively have an entire hemisphere of light.</p><p>Another interesting trick we can play is to have multi-colored lights. Press the
                    <span class="keycap"><strong>2</strong></span>; this will change to a texture that contains spots of various
                different colors.</p><div class="figure"><a name="d0e16205"></a><p class="title"><b>Figure&nbsp;17.6.&nbsp;Colored Spotlight</b></p><div class="figure-contents"><div class="mediaobject"><img src="ColoredProjectLights.png" alt="Colored Spotlight"></div></div></div><br class="figure-break"><p>This kind of complex light emitter would not be possible without using a texture.
                Well it could be possible without textures, but it would require a lot more
                processing power than a few matrix multiplies, a division in the fragment shader,
                and a texture access. Press the <span class="keycap"><strong>1</strong></span> key to go back to the flashlight
                texture.</p><p>There is one final issue that can and will crop up with projected textures: what
                happens when the texture coordinates are outside of the [0, 1] boundary. With
                previous textures, we used either <code class="literal">GL_CLAMP_TO_EDGE</code> or
                    <code class="literal">GL_REPEAT</code> for the S and T texture coordinate wrap modes.
                Repeat is obviously not a good idea here; thus far, our sampler objects have been
                clamping to the texture's edge. That worked fine because our edge texels have all
                been zero. To see what happens when they are not, press the <span class="keycap"><strong>3</strong></span>
                key.</p><div class="figure"><a name="d0e16227"></a><p class="title"><b>Figure&nbsp;17.7.&nbsp;Edge Clamped Light</b></p><div class="figure-contents"><div class="mediaobject"><img src="EdgeClampLight.png" alt="Edge Clamped Light"></div></div></div><br class="figure-break"><p>That rather ruins the effect. Fortunately, OpenGL does provide a way to resolve
                this. It gives us a way to say that texels fetched outside of the [0, 1] range
                should return a particular color. As before, this is set up with the sampler
                object:</p><div class="example"><a name="d0e16235"></a><p class="title"><b>Example&nbsp;17.7.&nbsp;Border Clamp Sampler Objects</b></p><div class="example-contents"><pre class="programlisting">glSamplerParameteri(g_samplers[<span class="code-number">1</span>], GL_TEXTURE_WRAP_S, GL_CLAMP_TO_BORDER);
glSamplerParameteri(g_samplers[<span class="code-number">1</span>], GL_TEXTURE_WRAP_T, GL_CLAMP_TO_BORDER);

<span class="code-keyword">float</span> color[<span class="code-number">4</span>] = {<span class="code-number">0.0f</span>, <span class="code-number">0.0f</span>, <span class="code-number">0.0f</span>, <span class="code-number">1.0f</span>};
glSamplerParameterfv(g_samplers[<span class="code-number">1</span>], GL_TEXTURE_BORDER_COLOR, color);</pre></div></div><br class="example-break"><p>The S and T wrap modes are set to <code class="literal">GL_CLAMP_TO_BORDER</code>. Then the
                border's color is set to zero. To toggle between the edge clamping sampler and the
                border clamping one, press the <span class="keycap"><strong>H</strong></span> key.</p><div class="figure"><a name="d0e16248"></a><p class="title"><b>Figure&nbsp;17.8.&nbsp;Border Clamped Light</b></p><div class="figure-contents"><div class="mediaobject"><img src="BorderClampLight.png" alt="Border Clamped Light"></div></div></div><br class="figure-break"><p>That's much better now.</p><div class="sidebar"><p class="title"><b>Line Drawing</b></p><p>You may have noticed that the position and orientation of the light was shown
                    by three lines forming the three directions of an axis. These are a new
                    primitive type: lines.</p><p>Lines have a uniform width no matter how close or far away they are from the
                    camera. Point primitives are defined by one vertex, triangle primitives by 3. So
                    it makes sense that lines are defined by two vertices.</p><p>Just as triangles can come in strips and fans, lines have their own
                    variations. <code class="literal">GL_LINES</code> are like
                    <code class="literal">GL_TRIANGLES</code>: a list of independent lines, with each line
                    coming from individual pairs of vertices. <code class="literal">GL_LINE_STRIP</code>
                    represents a sequence of lines attached head to tail; every vertex has a line to
                    the previous vertex and the next in the list. <code class="literal">GL_LINE_LOOP</code> is
                    like a strip, except the last and first vertices are also connected by a
                    line.</p><p>This is all encapsulated in the Framework's <code class="function">Mesh</code> class.
                    The axis used here (and later on in the tutorials) is a simple </p></div></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="Tutorial 17.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="Tutorial 17.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="Tut17 Pointing Projections.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Chapter&nbsp;17.&nbsp;Spotlight on Textures&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="../index.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;Pointing Projections</td></tr></table></div></body></html>